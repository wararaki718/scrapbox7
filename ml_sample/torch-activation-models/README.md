# softmax & sigmoid

## setup

```shell
pip install torch
```

## run

```shell
python main.py
```

## memo

sigmoid

- 0 から 1 の範囲で出力

softmax

- 0 から 1 の範囲で出力。n_output の総和が 1 になる。

relu

- 0 以上の値を保持する。（0 以下は 0 に丸める。）

softmax

- 0 以上の値を出力
